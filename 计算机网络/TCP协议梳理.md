### TCP协议梳理：

这里主要是按照比较细节的方式梳理一下TCP协议中的知识点。

***



#### TCP协议：

##### 	总览：

​	在OSI七层模型中，每一层会将用户数据加上报头，报尾一般是可选的，只有在数据链路层才默认添加报尾。

- 用户数据添加应用层报头（Application Header，AH）形成应用层协议数据单元（Protocol Data Unit，PDU），而后交给下层表示层。
- 同理，表示层将其整体封装，加上表示层报头（Presentation Header，PH）
- 会话层报头（Session Header，SH）
- 传输层报头（Transport Header， TH）
- 网络层报头（Network Header，NH）
- 数据链路层的帧头帧尾（Data Link Header/Termination， DH/DT）
- 最后移交至物理层传输



还有一个四层模型，考到的不多，但值得注意：

- 应用层：DNS、FTP、HTTP、TELNET、SMTP、其他
- 传输层：TCP/UDP
- 网间层：ICMP、IGMP、IP
- 网络接口层：ARP/RARP、其他



**注意：ARP协议一般认为是工作在第二层的协议，我理解因为一般认为它只工作在内网中，不涉及路由器之间的传播（不跨网段）。**

- 传输层：段（Segment）
- 网络层：包（Packet）
- 数据链路层：帧（Frame）





***

##### 	TCP头部：

![TCP头部](/resources/TCP头部.jpg)

首先TCP头部长度为：20字节 + 可选字段（最大为40字节），即总长**最大为60字节**



###### （1）16位端口号：

​	TCP通信时，**客户端**常常**自动选择临时端口号**，服务器则使用**知名服务端口号**。（定义在/etc/services文件中）

###### （2）32位序号：

​	连接时为报文段初始一个序列号，作为报文的按序排列的依据（解决乱序问题）。

​	一般初始化为一个随机值（Initial Sequence Number，ISN**出于安全考虑，不易被篡改和伪造**，但逻辑序号一般展示位1），后续的TCP报文段中序号值将被系统设置成 ISN 加上该报文段所携带数据的第一个字节在整个字节流中的偏移，如ISN+1025。 

###### （3）32位确认号：

​	响应另一方发来的TCP报文段，为其序列号加一。

###### （4）4位头部长度：

​	标识TCP头部有多少个32bit（4Byte）。四位最大15，即TCP头部**最长为60Byte**。

###### （5）6位标志位：

- 1) URG 标志，表示紧急指针（ urgent pointer）是否有效 。
- 2) ACK 标志，表示确认号是否有效，一般称携带 ACK 标志的 TCP 报文段为“确认报
  文段” 。
- 3) PSH 标志，提示接收端应用程序应该立即从 TCP 接收缓冲区中读走数据，为接收后续数据腾出空间（如果应用程序不将接收到的数据读走，它们就会一直停留在 TCP 接收缓冲区中）。
- 4) RST 标志，表示要求对方重新建立连接，一般称携带 RST 标志的 TCP 报文段为“复位报文段” 。
- 5) SYN 标志，表示请求建立一个连接，一般称携带 SYN 标志的 TCP 报文段为“同步
  报文段” 。
- 6) FIN 标志，表示通知对方本端要关闭连接了，一般称携带 FIN 标志的 TCP 报文段为“结束报文段” 。 

###### （6）16位窗口大小：

​	指的是接收通告窗口（Receiver Window，RWND）用来控制发送方速度。

###### （7）16位校验和：

​	CRC循环冗余算法，检验TCP报文段在传输过程中是否损坏。、

###### （8）16位紧急指针：

​	TCP 的紧急指针是发送端向接收端发送**紧急数据**的方法 。



另外：一个TCP连接需要一个五元组（src_ip, src_port, dst_ip, dst_port, 协议）





***

##### 	TCP状态流转：

​	其实，网络上的传输时没有连接的，包括TCP也是一样。

​	所谓TCP“连接”，其实是通信双方维护了一个“连接状态”，看上去像是有链接的。**所以TCP状态变换是非常重要的**。

![tcp状态机](/resources/tcp状态转换.jpg)

这块有几个不熟悉的点：

- FIN_WAIT2：表示半连接，一方要求关闭连接，另一方则还有部分数据，稍后关闭。
- TIME_WAIT：收到FIN并发送了ACK，等待2MSL关闭连接到CLOSED状态。
- CLOSING：较为少见。双方同时受到对方的FIN报文，即几乎在同一时间关闭socket会出现这种情况。
- CLOSED_WAIT：已发送FIN并收到ACK，等待对方是否有数据继续传输。

​	**2MSL状态：**是避免ACK未收到，对方再度重发FIN的情况，防止串话。但是会造成socket在一定时间无法再建立连接的情况。

​	**平静时间：**在2MSL时间内，虽然不能建立连接，但不会因为其他客户端连接这个端口而报错。





​	三次握手建立连接，四次挥手断开连接，在这就不介绍了。

​	断开连接的时候有一个状态叫做半连接，是因为TCP是全双工的，需从两个方向断开连接，所以出现了这种半关闭的状态。

![三次握手四次挥手](/resources/三次握手四次挥手.jpg)

###### 为什么需要三握四挥？

​	这边我一开始背的那份资料只是讲到了资源浪费的问题，但是我认为没有讲到本质。

​	对于建连接的 3 次握手，主要是要初始化 Sequence Number 的初始值。 通信的双方要互相通知对方自己的初始化的 Sequence Numbe一所以叫 SYN ， 也就上图中的x和y。 这个号要作为以后的数据通信的序号，**以保证应用层接收到的数据不会因为网络上的传输问题而乱序**（ TCP 会用这个序号来拼接数据） 。
​	对于 4 次挥手，其实仔细看则是两次，因为 TCP 是全双工的，所以，发送方和接收方
都需要独立地关闭即 FIN 和 ACK。 只不过，有一方是被动的，所以看上去就成了所谓的 4 次挥手。 **如果两边同时断连接，那就会就进入到 CLOSING 状态**，然后到达 TIME_WAIT 状态 。![tcp双方同时断连接](/resources/tcp双方同时断连接.png)

 

#### 补充：

- **关于建立连接时SYN超时：**如果client发送SYN后，由于某种原因掉线了，server收到SYN发送ACK，但一直未得到回复，那么server将一直处于某个中间状态。server会认为ACK传输丢失，所以server会不断重传ACK。在LINUX下，默认重传为5次，时间间隔每次double，分别为1s、2s、4s、8s、16s、32s，共63秒才能断开，这样会造成长时间的等待，资源利用率很低。
- **关于SYN Flood攻击：**从上面情况得知，向服务端发很多SYN，然后下线，服务端会不断重发ACK，每次都等待63s，使得正常连接无法处理。解决办法：
  - LINUX下有一个tcp_snycookies队列：在队列满了后，TCP会通过源地址和源端口和时间戳，发送一个确认的cookie，如果没有得到相应，则说明是恶意攻击，直接丢掉。
  - 还可以调整tcp_synack_retries来减少重传次数
  - 还可以调整tcp_max_syn_backlog来增大SYN连接数
  - 干脆处理不完的就直接丢弃。
- **关于ISN的初始化：**RFC793说，ISN会和一个假的时钟绑在一起，没4微秒对其加一，直到超过2^32归零继续。一个ISN周期总共4.55个小时，一般远大于MSL（Maximum Segment Lifetime），不会出现重用乱序问题。
- **关于MSL和TIME_WAIT：**一般MSL为2min，LINUX下为30s。2MSL为第一个FIN发送过去和之后发回ACK的传输时间。
- **Sequence Number：**序列号的增加是和传输的字节数相关的，如ISN+1460。一般抓包工具显示的0,1都是相对序号，为了方便表示。





***

##### 	TCP重传机制：

​	tcp网络异常的情况（**出现以下情况就会超时重传**）：![tcp传输异常](/resources/tcp传输异常.jpg)

超时重传定义：**TCP 每发送一个报文段，就对这个报文段设置一次计时器。 只要计时器设置的重传时间到了，但还没有收到确认，就要重传这一报文段，这个就叫作“超时重传” 。 **



重传机制效率的影响因素，重传时间RTO（Retransmission TimeOut，重传超时时间），指发送端在发送数据后，重传数据前等待接收方收到该数据报文ack的时间。

- 设长了：重发慢，没有效率， 性能差
- 设短了：重发快，增加网络拥塞，可能造成更多重发

RTO设置的挑战：

- 不同目的端的时延不同
- 时延会随业务负载的增加而变化



###### 自适应算法：

tcp采用自适应算法（Adaptive Retransmission Algorithm）：为了动态地设置，tcp引入了RTT（Round Trip Time）也即一个数据包从发出到回来的时间，RTT = t1(收到ack) - t0(发送包)，**这只是一个采样，不能代表普遍情况**。

- 经典算法：
  - 先采样RTT
  - 平滑计算SRTT = ( α \* SRTT ) + ((1- α) \* RTT) 其中α取值在0.8到0.9之间
  - 计算RTO = **min [ UBOUND,  max [ LBOUND,   (β \* SRTT) ]  ]**其中β在1.3到2.0之间，UBOUND是最大的timout时间，上限值，LBOUND是下限值
- Karn算法：
  - 针对的是网络情况的差异，比如第一次发数据，没有收到ack，重传之后才有收到ack，时间会算大；或者由于网络原因ack传回来之前已经重传了，时间会算小![Karn-Partridge-Algorithm](/resources/Karn-Partridge-Algorithm.jpg)
  - 所以**忽略重传，不把重传的RTT做采样**
  - 每次一发生重传，则把当前RTO值翻倍
- Jacobson/Karels算法：
  - **SRTT** **= S****RTT** **+ α** **(****RTT** **– S****RTT)**  —— 计算平滑RTT
  - **DevRTT** **= (1-β****)\*DevRTT** **+ β*****(|****RTT-SRTT|)** ——计算平滑RTT和真实的差距（加权移动平均）
  - **RTO= µ \* SRTT + ∂ \*DevRTT** —— 神一样的公式
  - （其中：在Linux下，α = 0.125，β = 0.25， μ = 1，∂ = 4 ——这就是算法中的“**调得一手好参数**”，nobody knows why, it just works…） 最后的这个算法在被用在今天的TCP协议中



另外就是tcp重传发送数据策略的问题：

比如12345，收到了12和45未收到3，发送方只收到了ack=3，但不知道是只发送3还是345都发送一遍。

- 只发送3，节省带宽，但是有可能45也丢了，需要继续重传，速度就慢了。
- 发送345，浪费带宽，但是快一点，不用考虑后续重传的问题。



###### 快速重传机制（解决死等问题）：

Fast Retransmit：**不以时间驱动，而以数据驱动重传**。如果包没有连续到达，就ack那个可能丢了的包的序号，接收方收到连续三个相同的ack就重传。



###### SACK方法：

选择确认法（Selective Acknowledgement），需在TCP头的可选项里面加一个SACK，ACK还是快重传的ACK，SACK则汇报收到的数据碎片。![tcp_sack_example](/resources/tcp_sack_example.jpg)

这样就解决了到底重传一个包还是全部重传的问题。

但是实际运行过程中，接收方由于缓冲区等问题，可能会丢弃SACK的数据，所以最终还是要按照ACK来发送数据。



###### Duplicate SACK收到重复数据问题（ACK > SACK说明重复了）：

又称D-SACK，其主要是使用SACK告诉发送方有哪些数据被重复接收了。

D-SACK使用了SACK的第一个段来做标志（可以有好几段，表示收到的断续包）

- 如果SACK的第一个段的范围被ACK所覆盖，那么就是D-SACK
- 如果SACK的第一个段的范围被SACK的第二个段覆盖，那么就是D-SACK



例1：ACK丢包

​	如下抓包示例，丢了两个ACK，发送端重发了第一个数据包（3000-3499），于是接收端发现重复收到，回了一个SACK=3000-3500，因为ACK都收到了4000之前的所有数据，所以此SACK为D-SACK。

​	这样可以告诉发送端收到了重复数据，而且发送端知道数据包没有丢失，而是ACK丢失。

```
Transmitted  Received    ACK Sent
Segment      Segment     (Including SACK Blocks)
 
3000-3499    3000-3499   3500 (ACK dropped)
3500-3999    3500-3999   4000 (ACK dropped)
3000-3499    3000-3499   4000, SACK=3000-3500
                                    ---------
```

例2：网络延误

​	如下抓包示例，网络包（1000-1499）被网络延误了，导致发送方没有收到ACK，而后面到达的三个包**触发了快重传**算法，所以重传，但重传时被延误的包收到了。所以回复SACK=1000-1500，因为ACK已经到了3000，所以此SACK为D-SACK，说明重复了。

​	此处，发送端知道之前因为快重传，触发了重传不是因为发出去的包丢了，也不是回应的ACK包丢了，而是网络延误了。

```
Transmitted    Received    ACK Sent
Segment        Segment     (Including SACK Blocks)
 
500-999        500-999     1000
1000-1499      (delayed)
1500-1999      1500-1999   1000, SACK=1500-2000
2000-2499      2000-2499   1000, SACK=1500-2500
2500-2999      2500-2999   1000, SACK=1500-3000
1000-1499      1000-1499   3000
               1000-1499   3000, SACK=1000-1500
                                      ---------
```

可见，引入了D-SACK，有这么几个好处：

1. 可以让发送方知道，是发出去的包丢了，还是回来的ACK包丢了。
2. 是不是自己的timeout太小了，导致重传。
3. 网络上出现了先发的包后到的情况（又称reordering）
4. 网络上是不是把我的数据包给复制了。

**<u>知道这些东西可以很好得帮助TCP了解网络情况，从而可以更好的做网络上的流控。</u>**





****

##### 	TCP滑动窗口：

​	**TCP头里有一个字段叫Window，又叫Advertised-Window，这个字段是<u>接收端告诉发送端自己还有多少缓冲区可以接收数据</u>**。**于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来**。

滑动窗口体现的是TCP面向字节流的设计思路。它的主要作用有两个：

- 提供TCP的可靠性
- 提供TCP的流控特性

TCP的窗口是一个16bit的字段，表示的是窗口字节容量，最大为2^16-1=65535个字节。

另外TCP的**选项字段**还包括一个TCP**窗口扩大因子**，option-kind为3，option-length为3，option-data取值范围为0-14。窗口扩大因子来TCP窗口，最多扩大为32bit。



###### 滑动窗口分为发送方窗口和接收方窗口两个：

**发送方**在缓冲区内的数据可以分为4类：

1. 已经发送并收到对端ACK
2. 已经发送但未收到对端ACK
3. 未发送但**对端允许发送**（即接收方有空间）
4. 未发送且对端不允许发送（即接收方无空间）

![tcpslidingwindows](/resources/tcpslidingwindows.png)



**接收方**在缓冲区内的数据可以分为3类：

1. 已接收
2. 未接收但准备接收（接收窗口）
3. 未接收且未准备接收



这边要提醒一下，TCP是全双工的协议，会话双方各自维护一个“发送窗口”和一个“接收窗口”。**一般“发送窗口”取决于对方通知的“接收窗口”。**



###### Zero Window问题：

​	如果一个**处理缓慢**的接收端，发送端在发送过程中，接收端无法及时处理，接收窗口不断减小，**最终减小到0**。这种情况下，发送端停止发送数据，但如果接收方窗口可用了，这样怎么通知发送端呢？

​	TCP采用Zero Window Probe技术，减到0后，发送端继续发送ZWP包给接收端，接收端会ack窗口尺寸。一般30-60s发一次，默认发送3次后，会发RST关闭连接。

（**注意**：只要有等待的地方都可能出现DDoS攻击，Zero Window也不例外，一些攻击者会在和HTTP建好链发完GET请求后，就把Window设置为0，然后服务端就只能等待进行ZWP，于是攻击者会并发大量的这样的请求，把服务器端的资源耗尽。）



###### Silly Window Syndrome问题：

​	和上个问题类似，也是一种接收端处理缓慢的问题，但是窗口没有减小到0，而是减小至只有几个字节的窗口。接收方每次发送的数据很小，但是要加上至少40个字节的报头（IP+TCP），造成很大开销。（**Silly Windows Syndrome这个现像就像是你本来可以坐200人的飞机里只做了一两个人**。）

​	**网络上有个MTU，对于以太网来说，MTU是1500字节，除去TCP+IP头的40个字节，真正的数据传输可以有1460，这就是所谓的MSS（Max Segment Size）注意，TCP的RFC定义这个MSS的默认值是536，这是因为 [RFC 791]里说了任何一个IP设备都得最少接收576尺寸的大小（实际上来说576是拨号的网络的MTU，而576减去IP头的20个字节就是536）。**

​	解决办法分两块：

- 如果是接收端引起，则使用David D Clark's方案。当接收方窗口减小到某个值是，直接ack（0）,直到窗口大小大于或等于MSS或buffer一半为空时，再把window打开。
- 如果是发送端引起，则使用Nagle算法，基本思想就是攒数据到MSS再发。（tcp默认打开，在一些需要频繁发送小包的场景下需要手动关闭）



***

##### 	TCP拥塞控制：

​	（我们知道TCP通过一个timer采样了RTT并计算RTO，但是，**如果网络上的延时突然增加，那么，TCP对这个事做出的应对只有重传数据，但是，重传会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，于是，这个情况就会进入恶性循环被不断地放大。试想一下，如果一个网络内有成千上万的TCP连接都这么行事，那么马上就会形成“网络风暴”，TCP这个协议就会拖垮整个网络。**这是一个灾难。）

​	TCP不是一个自私的协议，当拥塞发生时，就把“道路”让出来，不去抢了。

###### 	

###### 拥塞控制主要是四个算法：

1. 慢启动
2. 拥塞避免
3. 快重传
4. 快恢复



###### 慢启动：

1. 连接建好的开始先初始化cwnd = 1，表明可以传一个MSS大小的数据。
2. 每当收到一个ACK，cwnd++; 呈线性上升
3. **每当过了一个RTT，cwnd = cwnd*2; 呈指数让升**
4. 还有一个ssthresh（slow start threshold），是一个上限，当cwnd >= ssthresh时，就会进入“拥塞避免算法”（后面会说这个算法）

（注：Linux 3.0后采用了这篇论文的建议——把cwnd 初始化成了 10个MSS。）



###### 拥塞避免：

接着上面第四步继续，一般来说ssthresh的值是65535，单位是字节，当cwnd达到这个值时后，算法如下：

1）收到一个ACK时，cwnd = cwnd + 1/cwnd

2）**当每过一个RTT时，cwnd = cwnd + 1**

这样就可以避免增长过快导致网络拥塞，慢慢的增加调整到网络的最佳值。很明显，是一个线性上升的算法。



当丢包的时候，出现两种情况：

- 等到RTO超时，重传数据包；sshthresh = cwnd/2，cwnd = 1进入慢启动
- 快重传收到3个D-ACK，则直接重传；sshthresh = cwnd/2，cwnd = cwnd/2计入快恢复



###### 快恢复：

快速重传和快速恢复算法一般同时使用。快速恢复算法是认为，**你还有3个Duplicated Acks说明网络也不那么糟糕**，所以没有必要像RTO超时那么强烈。 

- cwnd = sshthresh  + 3 * MSS （3的意思是确认有3个数据包被收到了）
- 重传Duplicated ACKs指定的数据包
- 如果再收到 duplicated Acks，那么cwnd = cwnd +1
- 如果收到了新的Ack，那么，cwnd = sshthresh ，然后就进入了拥塞避免的算法了。

但只依赖三个重复的ack，只重传ack的那个包，如过丢了好多包，则必须等待RTO，无法触发快重传了。

![tcp拥塞控制](/resources/tcp拥塞控制.jpg)

一个方法是使用SACK。但TCP的实现有时不支持SACK，则诞生了以下方法：

于是，1995年，TCP New Reno（参见 [RFC 6582]）算法提出来，主要就是在没有SACK的支持下改进Fast Recovery算法的——

- 当sender这边收到了3个Duplicated Acks，进入Fast Retransimit模式，开发重传重复Acks指示的那个包。如果只有这一个包丢了，那么，**重传这个包后回来的Ack会把整个已经被sender传输出去的数据ack回来。如果没有的话，说明有多个包丢了。我们叫这个ACK为Partial ACK。**

- 一旦Sender这边发现了Partial ACK出现，那么，sender就可以推理出来有多个包被丢了，于是乎**继续重传sliding window里未被ack的第一个包。**直到再也收不到了Partial Ack，才真正结束Fast Recovery这个过程

我们可以看到，这个“Fast Recovery的变更”是一个非常激进的玩法，他同时延长了Fast Retransmit和Fast Recovery的过程。



###### FACK算法：

​	FACK全称Forward Acknowledgment 算法，论文地址在这里（PDF）[Forward Acknowledgement: Refining TCP Congestion Control](http://conferences.sigcomm.org/sigcomm/1996/papers/mathis.pdf) 这个算法是其于SACK的，前面我们说过SACK是使用了TCP扩展字段Ack了有哪些数据收到，哪些数据没有收到，他比Fast Retransmit的3 个duplicated acks好处在于，前者只知道有包丢了，不知道是一个还是多个，而SACK可以准确的知道有哪些包丢了。 所以，SACK可以让发送端这边在重传过程中，把那些丢掉的包重传，而不是一个一个的传，但这样的一来，如果重传的包数据比较多的话，又会导致本来就很忙的网络就更忙了。所以，FACK用来做重传过程中的拥塞流控。





***

##### 	TCP可选字段：

​	TCP 头部的选项部分是为了 TCP **适应复杂的网络环境和更好地服务于应用层**而进行设计的 。TCP 选项部分最长可以达到 40 Byte ，再加上 TCP 选项外的固定的 20 Byte 部分， TCP的最长头部可达 60 Byte。 



###### （1）SO_REUSEADDR：

​	一般来说，一个端口释放后会等待2MSL才能被使用，大概2分钟；设置了SO_REUSEADDR则可以**让端口释放后就可以被立即使用**。**作用于处于TIME_WAIT状态下的套接字**。在bind前设置。

- 允许启动一个监听服务器并捆绑器总所周知的端口，并且以前建立的将此端口用作本地端口的连接仍存在。
- 允许在同一个端口上启动同一个服务器的多个实例，只要每个实例捆绑一个不同本地IP地址即可。
- 允许单个进程捆绑同一个端口到多个套接口上，只要每个进程捆绑的制定不同IP地址即可。
- 允许当一个IP地址和端口绑定到某个套接口上时，还允许此IP地址和端口捆绑到另一个套接口上。

（须慎用：在编写 TCP/SOCK STREAM 服务程序时， SO REUSEADDR 这个套接宇选项会通知内核，**如果端口忙，但 TCP 状态位于 TIME WAIT 状态，则可以重用端口**；如果端口忙，而 TCP 状态位于其他状态，重用端口时依旧会得到一个错误信息，指明“地址已经使用中” 。 **如果服务程序停止后想立即重启，而新套接字依旧使用同一端口，此时使用 SO_ REUSEADDR 选项非常有用 。**）



###### （2）TCP_NODELAY/TCP_CORK：

​	网络拥塞时，由于发送方窗口的减小，每次发送小数据包开销非常大（Silly Window Syndrome），要解决这个问题，有一个非常有名的Nagle算法。

- 统一称长度小于 MSS 的数据包为小包
- 与此相对，称长度等于 MSS 的数据包为大包
- 为了某些对比说明，还有中包，即长度比小包长，但又不足一个MSS 的包

**算法描述：**

​	如果发送端欲多次发送包含少量字符的数据包，则发送端会先将**第一个**小包发送出去，而将后面到达的少量字符数据都**缓存起来而不立即发送**，直到收到接收端对前一个数据包报文段的 ACK 确认为止，或当前宇符属于**紧急数据**，或者**积攒到了一定数量**的数据（比如缓存的字符数据已经达到数据包报文段的最大长度）等多种情况才将其**组成一个较大的数据包**发送出去 。 

TCP_NODELAY：不适用Nagle算法，直接发小包。

TCP_CORK：意为“塞子”，每次发送延迟200ms，尽量发送最大的数据量。



###### （3）SO_LINGER：

​	linger意为“延迟，延缓”，指**延缓**面向连接的**socket的close操作**。默认close立即返回，但是当发送缓冲区中海油一部分数据时，系统会尝试将数据发送给对端。

```C++
struct linger{
	int l_onoff;  //0=off , nonzero=on 
	int l_linger; // liner time, POSIX specifies units as seconds
}；
```

这里面有几个重要概念：

1. 1_onoff设置为0，那么linger被忽略，close立即返回。如果send buffer中还有数据，则会等到所有数据发送完毕后返回。（**只能保证数据已经发送到对方，所以并不知道对方是否已经接受了数据** ）

2. 1_onoff设置为非0，1_linger设置为0，close()不被阻塞立即执行，丢弃socket发送缓冲区中的数据，并向对端发送一个RST报文。强制关闭，TCP不会进入TIME_WAIT状态。

3. **1_onoff设置为非0，1_linger设置为非0，则close()调用阻塞进程，直到所剩的数据发送完毕或者超时。称为“优雅关闭“。**

   调用 close 去关闭 socket 的时候，内核将会延迟。 也就是说，如果 send buffer 中还有数据尚未发送，**该进程将会被休眠直到**以下任何一种情况发生：  

   - ① send buffer 中的所有数据都被发送并且得到对方 TCP 的应答消息（**这种应答对方已经接收到数据，并不保证对方应用程序已经读取数据**）。
   - ②延迟时间消耗完，在延迟时间被消耗完之后 ， send buffer中的所有数据都将会被丢弃 。 

4. shutdown等待应用程序读取数据

   调用shutdown后立即调用read，read会被阻塞，知道接收到对方的FIN标志，即**read是在服务端应用程序调用close之后才返回的**。

   当服务器端应用程序读取到来自 client 的数据和 FIN 标志之后，服务器端会进入 CLOSE_WAIT 状态，那么，如果此时服务器端要断开该 TCP 连接，需要服务器端应用程序调用一次 close ，也就意味着向 client 发送一次 FIN 标志 。 这个时候，说明服务器端的应用程序已经读取到 client 发送的数据和 FIN 标志， read 会在接收到服务器端的 FIN 之后返回 。 所以，**shutdown 可以确保服务器端应用程序已经读取数据了**，而不仅仅是服务器端已经接收到数据而己 。



###### (4)  TCP_DEFER_ACCEPT

​	defer accept，从字面上理解是**推迟接收**，**实际上是当接收到第一个数据之后，才会创建连接** 。 对于像 HTTP 等非交互式的服务器，这个很有意义，**可以用来防御空连接攻击**。 

```C++
val = 5 ;
setsockopt(srv_socket->fd, 
           SOL_TCP, 
           TCP_DEFER_ACCEPT, 
           &val, 
           sizeof (val)) ; 
//kernel 在 val 时间之内还没有收到数据，不会继续唤醒进程，而是直接丢弃连接 。  
```



###### (5)SO_KEEPALIVE(若没设置，则不会发送保活探测)

​	**用于保持连接检测对方主机是否崩溃，避免服务器永远阻塞于TCP连接的输入。**

- 设置该选项后，如果**2h**（默认值）内该socket任一方都没有数据交换，则TCP发送一个**保持存活探测分节（keepalive probe），对方必须响应。**
  - 对方一切正常：则响应ACK；2h后重发探测分节。
  - 对方已崩溃且已重启：以RST响应，套接口关闭；套接口的待处理错误被置为 ECONNRESET 。
  - 对方无任何响应：另外发送8个探测分节，75s一个（共11min15s），如果仍无响应就放弃，套接口关闭。套接口的待处理错误被置为ETIMEOUT 。  





***

#### 网络字节序和主机序：

​	不同的 CPU 有不同的字节序类型，这些**字节序是指整数在内存中保存的顺序，称为主机序** 。 最常见的有两种：

1. 小端（Little Endian） ，将低序字节存储在起始地址。
2. 大端（Big Endian） ，将高序字节存储在起始地址 。 

**JAVA语言统一使用大端，C/C++则根据编译平台所属CPU有关。**

**网络协议也都采用大端来传输数据，即网络字节序。**





****

#### 封包和解包：

​	TCP 是个“流”协议，所谓流，就是没有界限的一串数据 。 大家可以将其想象河里的流水，是连成一片的，其间是没有分界线的。

​	由于 TCP “流”的特性以及网络状况，在进行数据传输时假设我们连续调用两次 send 分别发送两段数据 data1 和 data2,在接收端有以下几种接收情况（当然不止这几种情况，这里只列出了有代表性的情况）。

1. 先接收到 datal ，然后接收到 data2 。
2. 先接收到 datal 的部分数据，然后接收到 datal 余下的部分以及 data2 的全部。
3. 先接收到了 datal 的全部数据和 data2 的部分数据，然后接收到了 data2 的余下的
   数据。
4.  一次性接收到了 datal 和 data2 的全部数据 。 

**其中2,3,4称为“粘包”需要进行拆包，需要再发送端进行封包。**

引起粘包的情况：

- Nagle算法
- 接收端接收不及时



​	封包，加上包头，包头是个固定结构体，其中有个标识包体长度的变量，接收方利用缓冲区，不断拆包头，读取相应长度的数据（**注意网络字节序和CPU的主机序**）。

​	为了解决“粘包”的问题，大家通常会在所发送的内容前加上发送内容的长度，所以对方就会**先收 4 Byte ，解析获得接下来需要接收的长度，再进行收包** 。 

